% 11 pages
This chapter will lay foundations for medical imaging for clinical diagnostics and the basic methodology used throughout this thesis to tackle advanced imaging diagnostics.

\section{Clinical Background: Volumetric Medical Imaging} %4 pages

% Ideas:
% zhang2024challenges (foundation models in deep learning)
% https://3dqlab.stanford.edu/what-is-3d-imaging-2/

    \subsection{Diagnostic Disciplines and Tasks} %1 pages
        What is Medical volumetric Imaging used for in general?


        "This article celebrates this breadth of scientific discovery and develop-ment by examining the impact that CT has had on the di-agnosis, characterization, and management of a sampling of major health challenges,
        1111 including stroke, vascular dis-eases, cancer, trauma, acute abdominal pain, and diffuselung diseases, 1111
        as related to key technical advances in CT and manifested in Radiology." \cite{rubin2014computed}

        a substantialchange in overall volume can be seen on three-dimensional images (C and F) (fig 1 from reference 271). \cite{rubin2014computed}

        . With the introduction ofvolumetric CT, the ability to discrim-inate global and regional growth im-proved greatly, allowing estimation ofdoubling times (271) and providingprincipled approaches to followinglung nodules (256,272) (Fig 13). \cite{rubin2014computed}


        Tissue vol-ume quantification was established forthe left cardiac ventricle (343), cere-bral spinal fluid (344), liver and spleen(345), and tumoral neoplasia (346) allwithin the 1st decade after the intro-duction of CT. \cite{rubin2014computed}

        Within this con-text, the need to reformat, reconstruct,and render CT images into alternativedisplays was driven by a desire to pro-vide all physicians with an understand-ing of the anatomic nuances that CTprovided in a manner that might beencountered in the surgical suite. Al-though computers and computation arefundamental to CT, the applications ofcomputer graphics, vision, and quan-titation methods were not sufficientlymature to make their use routine un-til the latter days of the 20th century. \cite{rubin2014computed}


        s. One quickly meet challenges associated to memoryand compute consumption when using CNNs with higher-dimensional image data, challenges thatresearchers are trying various approaches to deal with (treating 3D as stacks of 2Ds, patch- orsegment-based training and inference, downscaling, etc). It is clear that the ideas behind state-of-the-art two-dimensional CNNs can be lifted to three dimensions, but also that adding a thirdspatial dimension results in additional constraints. \cite{lundervold2019overview}

        The 1.5T clinical MRI was launched as a commercially avail-able clinical system in the early 1980s. \cite{kabasawa2022mr}


        Broadly speaking, thereare three distinct imaging objectives: to detect, resolve, and characterizeabnormalities \cite{abramson2023surgeons}

        . MRI sequences, on the other hand, can be tailored towards one ormore of these goals by altering the trade-off between resolution,contrast, and noise. A traditional T2 fat suppressed sequence is excellentfor tumor detection, as most tumors are T2 bright and standout againstthe dark (suppressed) fat. However, these sequences are often 5 mmthick with gaps between slices, maximizing signal to noise but limitingresolution. \cite{abramson2023surgeons}.

        It is overly simplistic to state that CT has high spatial resolution andMRI exhibits excellent contrast. \cite{abramson2023surgeons}

        However, when greater soft tissue contrast isrequired, there currently is no substitute for MRI. \cite{abramson2023surgeons}

        utting-edge CTtechniques, including the use of more sensitive photon counting de-tectors3 and dual energy data acquisition,4,5 will increase CT spatial resolution and contrast while minimizing noise, but this is unlikely toovercome the multitude of MR sequences tailored to images varioustissues throughout the body.  \cite{abramson2023surgeons}

        % DL specific
        \cite{litjens2017survey}
        \cite{piccialli2021survey}

        How does it differ from non-volumetric imaging?
        Why are CT and MRI so important?
        Why is US not explained in this thesis?

        Volumetric medical imaging enables the diagnosis of xyz.
        % How did volumetrict Medical Imaging evolve
        CT and MRI are often done paired follow ups? This is why these are in focus.
        CT (and PET) and MRI are important imaging domains.
        CT was invented in xyz and evolved to abc.
        MRI was invented in xyz and evolved to abc.
        % How important is volumetric imaging?

        % How important is MRI
        % How important is CT
        % Which different disciplines are common? What are challenges?

    \subsection{Imaging Domains and Scanner Properties} %1.5 pages
    % What are the special benefits and downsides of CT, MRI?
    \subsection{Generalization: Possibilities and Challenges} %1.5 pages
        % What makes Generalization hard?
        % What can be done to achieve generalization in each of the steps?

\section{Methodological Background: Deep Learning} %7 pages
    % TODO: This needs to be a lot shorter now
    % https://books.google.de/books?hl=de&lr=&id=qOF4AgAAQBAJ&oi=fnd&pg=PP1&ots=vNTiX5Lu_U&sig=UEC7rljJ7dVsAbh_XQeMmCrNqcU#v=onepage&q&f=false
    The principal mechanisms of learning were studied in the last century by investigating conditioned learning, where an outcome is associated to a stimulus by a learning organism e.g. a dog that awaits food after hearing the sound of a bell \citep{pavlov1928conditioned, pavlov2010conditioned, banich2011generalization}. Later, fear responses were especially studied and two sub-mechanisms of conditioned learning --- generalization and specialization --- were discovered \citep{banich2011generalization}.
    In fear learning, initially an instance-based generalization occurs that maps a novel fear to an environment \citep{banich2011generalization}. Later, this generalization is specialized and mapped to specific environmental stimuli leading to discrimination \citep{banich2011generalization}.
    It was discovered, that generalization can occur intra-modal and cross-modal for the example of the food awaiting dog either receiving visual or auditory stimuli \citep{pavlov1928conditioned} and that gradients of generalization exist \citep{guttman1956discriminability}.
    The concept of gerneralization and spezialization can be tracked down to individual parts of the brain, where the initial generalized learning is associated to the amygdala whereas the specialization occurs in the prefrontal cortex and the hippocampus \citep{banich2011generalization}.

    On the cell level, learning and building memory is assumed to work as the change of neuron connection-strength through synaptic plasticity \citep{do1949organization,martin2000synaptic}. Apart from synaptic information exchange it was also figured out that information exchange occurs volumetrically between glia cells and neurons with extracellular vesicles in the nervous system \citep{schiera2019communcation}.

    \subsection{Basic Principles} % 1 pages
        % https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html

        Inspired by the research findings in biological learning processes, \citeauthor{mcculloch1943logical} decribed several parts of network structures mimicking neural systems \citep{mcculloch1943logical}.
        Over a decade later \citeauthor{rosenblatt1957perceptron} developed the concept of a \emph{perceptron} as a learning element for electronic or electromechanical systems to recognize patterns \citep{rosenblatt1957perceptron}.
        First real classification experiments were conducted by \citeauthor{widrow1960adaptive} using small neural networks \citep{widrow1960adaptive}.
        % TODO: were those exp based on value tables? vs. backprop?
        More than two decades later the \emph{Backpropagation} mechanism was developed, that is nowadays used in current deep learning approaches to systematically configure the weights and biases of neural networks \citep{rumelhart1986learning}.

        % With increasing computational power and availability of large data through the internet machine learning techniques experienced increased interest \citep{xx}.

        \paragraph{Backpropagation} The basic principle of deep learning is the backpropagation mechanism.

        \begin{align}
            \diffp{E}{{y_j}} &= y_j - d_j \\
            \diffp{E}{{x_j}} &= \diffp{E}{{y_j}} \cdot \diffp{{y_j}}{{x_j}}
        \end{align}

        % Now that we know how deep learning works in general, we can have a look at individual building blocks models / data concepts / supervision tasks

    \subsection{Data Representation and Model Architectures} % 2 pages

        \subsubsection{Convolutional Neural Networks}
            % cnns, unets
            % cnn Kernels
        \subsubsection{Graph Neural Networks}
            % feature aggregation
            % rota groups, equivariance,

    \subsection{Training and Optimization Strategies} % 3 pages
        % curriculum learning, dice loss
        % metrics

    \subsection{Generalization: Recent Discussion and Approaches} % 1 pages
        % What are the current approaches in deep learning? How is the idea of AGI related to our gerneralization approach? What can be problems of AGI and why do we analyse generalization in a limited scope such as medical image analysis?
        % generalization methods